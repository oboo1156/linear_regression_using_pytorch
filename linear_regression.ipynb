{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIBqw6XAT4dR"
      },
      "source": [
        "#!pip install numpy torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aW17XrpVXzp"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119]], dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5TR4udjcXNB",
        "outputId": "246b4e1c-e25e-4156-dd62-b70a8d231ada"
      },
      "source": [
        "# Convert inputs and targets to tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJiAY1zudHH8",
        "outputId": "61e44ebc-cabb-4683-800a-f13a9e5bf0fb"
      },
      "source": [
        "# we used 2x3 for weights because we predicting 2 variables(apples,oranges) and each formala is a set of 3 elements(w11,w12,w13).We represent weight with matrix\n",
        "#We represent weight with biase as a vector thats why its only number 2 \n",
        "w = torch.randn(2, 3, requires_grad=True) # w or m derivative , -(2/n)*sum(x*(y-y_predicted))\n",
        "b = torch.randn(2, requires_grad=True) #b derivative , -(2/n)*sum(y-y_predicted)\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.8323,  0.1733, -0.9786],\n",
            "        [ 0.4811,  0.0117, -0.1622]], requires_grad=True)\n",
            "tensor([3.0281, 0.9385], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOiwKLp7f181"
      },
      "source": [
        "Our model is simply a function that performs a matrix multiplication of the inputs and the weights w (transposed) and adds the bias b (replicated for each observation).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMpJ2DYXdHK3",
        "outputId": "59f69c46-bb6a-40f1-a069-f15e12c10c12"
      },
      "source": [
        "inputs @ w.t() + b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -88.1964,   29.8719],\n",
              "        [-120.0883,   35.3724],\n",
              "        [-102.9160,   34.9591],\n",
              "        [-110.6206,   44.5173],\n",
              "        [-106.2630,   23.9079]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S8fehX8dHNP",
        "outputId": "7b486ffa-d3e3-4c10-889d-da2cef7cbc44"
      },
      "source": [
        "#defining model(linear regression)\n",
        "\n",
        "def model(x):\n",
        "  return x @ w.t() +  b\n",
        "\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ -88.1964,   29.8719],\n",
            "        [-120.0883,   35.3724],\n",
            "        [-102.9160,   34.9591],\n",
            "        [-110.6206,   44.5173],\n",
            "        [-106.2630,   23.9079]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecz1sBNtdHQf"
      },
      "source": [
        "def mse(preds, targets):\n",
        "    diff = preds - targets\n",
        "    return torch.sum(diff * diff) / diff.numel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1l9L3sDReqi",
        "outputId": "b80ca8a6-5785-4740-a428-0a551f5fa70e"
      },
      "source": [
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(19648.3340, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gqvLRzYQTNr"
      },
      "source": [
        "#compute gradient|  \n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vblNJw1QTRC",
        "outputId": "08879517-59bf-4883-c8b2-24932aeca46d"
      },
      "source": [
        "#The gradients are stored in the .grad property of the respective tensors. We call it by .grad method\n",
        "print(w)\n",
        "print(w.grad) #the value represent the derivative/gradient of the loss w.r.t(with respect to) the weight aboveðŸ‘†\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.8323,  0.1733, -0.9786],\n",
            "        [ 0.4811,  0.0117, -0.1622]], requires_grad=True)\n",
            "tensor([[-15219.7041, -16577.1230, -10299.3203],\n",
            "        [ -4645.1226,  -6081.3770,  -3598.0706]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8_oLGE-QTTi"
      },
      "source": [
        "#Gradient descent -> we are descending along the gradient by substracting a small amount from the gradient\n",
        "# Adjust weights & reset gradients\n",
        "with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRcBTmmhbHWw",
        "outputId": "e8784490-595e-4340-a412-7453b8d9b34d"
      },
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6801,  0.3391, -0.8756],\n",
            "        [ 0.5276,  0.0725, -0.1262]], requires_grad=True)\n",
            "tensor([3.0299, 0.9391], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fccAuXYXQTZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a4834ba-c1fa-4bf6-8cb9-690902fab3df"
      },
      "source": [
        "# Calculate loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(19648.3340, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhVZrFkPdYvI",
        "outputId": "096130c4-9870-46fe-fadf-af6a08eca56a"
      },
      "source": [
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWZPy2A7x_n0"
      },
      "source": [
        "Training the model using gradient descent optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr6z78DLyES4",
        "outputId": "5574a1a3-4fb9-444b-d498-7d5674ff202b"
      },
      "source": [
        "#step1: Generate predictions\n",
        "\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-61.5489,  38.8852],\n",
            "        [-85.0571,  47.2544],\n",
            "        [-61.4861,  49.2369],\n",
            "        [-84.1558,  53.2021],\n",
            "        [-72.6360,  35.4704]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxMG-aWNyg6n",
        "outputId": "a67a3f74-bdfb-4c6d-fda4-7de803d194aa"
      },
      "source": [
        "#step2: Calculate the loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(13419.7686, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtvXl-Bpyg9P",
        "outputId": "e7ce83f5-dfda-4a88-d49d-765d9fddd5e9"
      },
      "source": [
        "#step3: Compute Gradient\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-12468.2646, -13619.9385,  -8474.5469],\n",
            "        [ -3712.1094,  -5072.1426,  -2976.7019]])\n",
            "tensor([-149.1768,  -47.1902])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89I43MLhyhIi"
      },
      "source": [
        "#step4: Adjust weight and reset gradient\n",
        "with torch.no_grad():\n",
        "  w -= w.grad * 1e-5\n",
        "  b -= b.grad * 1e-5\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-n6dswL0Etz",
        "outputId": "90c8b74d-e7d5-4d3c-ddca-5db4636a803c"
      },
      "source": [
        "print(w,b , sep=\"\\n \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.5554,  0.4753, -0.7908],\n",
            "        [ 0.5647,  0.1232, -0.0964]], requires_grad=True)\n",
            " tensor([3.0314, 0.9396], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onvRb_ga1k7o",
        "outputId": "5b22c2ab-0759-4f23-ce04-cd8c48477ea9"
      },
      "source": [
        "#step5: Calculate the loss to see its reduction\n",
        "preds = model(inputs)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(9220.5107, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPWfuos-7Ny7"
      },
      "source": [
        "If the learning rate is too low the network might take several iterations and epochs to converge, on the opposite side of things, if the learning rate is too high, there is a risk of overshooting the minimum, and as a result of this our training doesnâ€™t converge.\n",
        "To reduce the loss further, we can repeat the process of adjusting the weights and biases using the gradients multiple times. Each iteration is called an epoch. Let's train the model for 100 epochs.\n",
        "#To reduce the loss further, we can repeat the process of adjusting the weights and biases using the gradients multiple times. Each iteration is called an epoch. Let's train the model for 100 epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkCpEQ712ANi"
      },
      "source": [
        "for epoch in range(1500):\n",
        "  preds = model(inputs)\n",
        "  loss = mse(preds,targets)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed2Cp9vG3uC1",
        "outputId": "851aca9a-0c91-4ac5-bdf1-d99c83d7a407"
      },
      "source": [
        "#calculate new loss\n",
        "preds = model(inputs)\n",
        "loss = mse(preds,targets)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(6.5299, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb36Vmof3jNc",
        "outputId": "cddc8216-e46f-4ada-9f15-e8b7cd7f68d5"
      },
      "source": [
        "#lets compare prediction from target\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 57.9070,  70.6387],\n",
              "        [ 79.9339,  99.1284],\n",
              "        [122.6797, 135.9380],\n",
              "        [ 22.1583,  37.8418],\n",
              "        [ 97.9371, 116.1582]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVo611lO6Dpl",
        "outputId": "e6d53aa1-22d1-4fbe-f3a0-6a1c2e76b664"
      },
      "source": [
        "#\n",
        "targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcDlinTnHFPm"
      },
      "source": [
        "Linear regression using PyTorch built-ins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvUtiXObHM7k"
      },
      "source": [
        "import torch.nn as nn #utility class for building neural network\n",
        "import numpy as np\n",
        "\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70], \n",
        "                   [74, 66, 43], \n",
        "                   [91, 87, 65], \n",
        "                   [88, 134, 59], \n",
        "                   [101, 44, 37], \n",
        "                   [68, 96, 71], \n",
        "                   [73, 66, 44], \n",
        "                   [92, 87, 64], \n",
        "                   [87, 135, 57], \n",
        "                   [103, 43, 36], \n",
        "                   [68, 97, 70]], \n",
        "                  dtype='float32')\n",
        "\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119],\n",
        "                    [57, 69], \n",
        "                    [80, 102], \n",
        "                    [118, 132], \n",
        "                    [21, 38], \n",
        "                    [104, 118], \n",
        "                    [57, 69], \n",
        "                    [82, 100], \n",
        "                    [118, 134], \n",
        "                    [20, 38], \n",
        "                    [102, 120]], \n",
        "                   dtype='float32')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Uq6eAIXJWUE",
        "outputId": "5b398359-0a47-4260-ce7a-6935cd085e75"
      },
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "\n",
        "print(inputs,targets, sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.],\n",
            "        [ 74.,  66.,  43.],\n",
            "        [ 91.,  87.,  65.],\n",
            "        [ 88., 134.,  59.],\n",
            "        [101.,  44.,  37.],\n",
            "        [ 68.,  96.,  71.],\n",
            "        [ 73.,  66.,  44.],\n",
            "        [ 92.,  87.,  64.],\n",
            "        [ 87., 135.,  57.],\n",
            "        [103.,  43.,  36.],\n",
            "        [ 68.,  97.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.],\n",
            "        [ 57.,  69.],\n",
            "        [ 80., 102.],\n",
            "        [118., 132.],\n",
            "        [ 21.,  38.],\n",
            "        [104., 118.],\n",
            "        [ 57.,  69.],\n",
            "        [ 82., 100.],\n",
            "        [118., 134.],\n",
            "        [ 20.,  38.],\n",
            "        [102., 120.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfk0s0N9JWXk",
        "outputId": "3562c64c-4fb2-4142-96ff-dc624da781bf"
      },
      "source": [
        "#for large dataset we train the model in batches other than that the dataset wont fit in memory or it will slow you down\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "#define data set\n",
        "train_ds = TensorDataset(inputs,targets)\n",
        "train_ds[:3]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.]]), tensor([[ 56.,  70.],\n",
              "         [ 81., 101.],\n",
              "         [119., 133.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAtV4oBBJWcU",
        "outputId": "36979cfe-a16e-482c-8d25-c7ee37c8092e"
      },
      "source": [
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds,batch_size , shuffle=True)#Shuffling helps randomize the input to the optimization algorithm, leading to a faster reduction in the loss.\n",
        "for xb, yb in train_dl:\n",
        "  print(xb,yb,sep='\\n')\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[101.,  44.,  37.],\n",
            "        [ 92.,  87.,  64.],\n",
            "        [ 88., 134.,  59.],\n",
            "        [ 91.,  87.,  65.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 21.,  38.],\n",
            "        [ 82., 100.],\n",
            "        [118., 132.],\n",
            "        [ 80., 102.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQx8f2YaJWkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e73b8e50-9ebb-4749-b63d-7be294489757"
      },
      "source": [
        "model = nn.Linear(3,2)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3394,  0.0763, -0.1223],\n",
            "        [-0.1840, -0.2718, -0.0303]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.3469,  0.1289], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgblO-iBUDH7",
        "outputId": "88b9a3af-72ca-4f32-cf41-837859afe1db"
      },
      "source": [
        "list(model.parameters())#help us see the list of weights and bias in our model. will see in the essence if we have multiple models and they contain multiple w&b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.3394,  0.0763, -0.1223],\n",
              "         [-0.1840, -0.2718, -0.0303]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.3469,  0.1289], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuktFuZuUDKg",
        "outputId": "cba26d0c-3cf7-4c76-99ad-02028f97e69a"
      },
      "source": [
        "#predictions\n",
        "preds = model(inputs)\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-25.2689, -32.8166],\n",
              "        [-32.3439, -42.4726],\n",
              "        [-26.7405, -54.0555],\n",
              "        [-36.2102, -31.4495],\n",
              "        [-25.0000, -40.7798],\n",
              "        [-25.6847, -32.7289],\n",
              "        [-32.5426, -42.2311],\n",
              "        [-27.2022, -54.2699],\n",
              "        [-35.7945, -31.5372],\n",
              "        [-24.7829, -40.6260],\n",
              "        [-25.4676, -32.5751],\n",
              "        [-32.7597, -42.3849],\n",
              "        [-26.5418, -54.2970],\n",
              "        [-36.4273, -31.6032],\n",
              "        [-24.5842, -40.8675]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6dtHtGYJWnn"
      },
      "source": [
        "#loss function by pytorch\n",
        "import torch.nn.functional as F #this function contains a lotta functions like activation function, loss function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN9y6k4kHM_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c58ff80-2fb5-4d22-9c3d-db2ff55bdef9"
      },
      "source": [
        "loss_fn = F.mse_loss\n",
        "loss = loss_fn(model(inputs), targets)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15663.5732, grad_fn=<MseLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuB5YN607kWU"
      },
      "source": [
        "#Optimizer/Gradient Descent(to perform update w and biase authomatically)\n",
        "#sgd=stochastic gradient descent. the descent is performed in randomm instead of group\n",
        "#from keras import optimizers\n",
        "#sgd = optimizers.SGD(lr=1)\n",
        "opt = torch.optim.SGD(model.parameters(),lr=1e-5)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2EmNCIJ_X9c"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "We are now ready to train the model. We'll follow the same process to implement gradient descent:\n",
        "\n",
        "1. Generate predictions\n",
        "\n",
        "2. Calculate the loss\n",
        "\n",
        "3. Compute gradients w.r.t the weights and biases\n",
        "\n",
        "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
        "\n",
        "5. Reset the gradients to zero\n",
        "\n",
        "The only change is that we'll work batches of data instead of processing the entire training data in every iteration. Let's define a utility function `fit` that trains the model for a given number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVHPe45Y7kZQ"
      },
      "source": [
        "def fit(num_epochs, model, loss_fn, opt, train_dl ):\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "     # Train with batches of data\n",
        "        for xb,yb in train_dl:\n",
        "\n",
        "          #1.generate prediction\n",
        "          preds = model(xb)\n",
        "\n",
        "          #2. calculate loss\n",
        "          loss = loss_fn(preds, yb)\n",
        "\n",
        "          #3.Compute gradients \n",
        "          loss.backward()\n",
        "\n",
        "          #4.update parameters(weights & biases). instead of doing torch.no_grad etc \n",
        "          opt.step()\n",
        "\n",
        "          #5.Reset the gradients to zero \n",
        "          opt.zero_grad()\n",
        "\n",
        "        if (epoch+1) % 10 == 0:\n",
        "          print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
        "\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIUSaNpRHnhx",
        "outputId": "059e6753-efd6-44f3-e328-4e5f708e8d25"
      },
      "source": [
        "fit(101, model,loss_fn, opt, train_dl )\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [10/101], Loss: 1.4160\n",
            "Epoch [20/101], Loss: 1.6135\n",
            "Epoch [30/101], Loss: 1.2748\n",
            "Epoch [40/101], Loss: 0.9689\n",
            "Epoch [50/101], Loss: 1.8887\n",
            "Epoch [60/101], Loss: 0.9176\n",
            "Epoch [70/101], Loss: 1.6120\n",
            "Epoch [80/101], Loss: 0.9516\n",
            "Epoch [90/101], Loss: 1.4199\n",
            "Epoch [100/101], Loss: 1.2017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axV_Fm3L7kcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c664aff1-67fa-47aa-dd70-e18390d0dbbb"
      },
      "source": [
        "preds = model(inputs)\n",
        "preds"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.8944,  70.4441],\n",
              "        [ 81.8240, 100.3168],\n",
              "        [118.6147, 133.2373],\n",
              "        [ 20.9183,  37.8712],\n",
              "        [101.3823, 118.0720],\n",
              "        [ 55.6459,  69.3602],\n",
              "        [ 81.6436, 100.3729],\n",
              "        [118.8922, 133.8163],\n",
              "        [ 22.1668,  38.9550],\n",
              "        [102.4503, 119.2121],\n",
              "        [ 56.7140,  70.5002],\n",
              "        [ 80.5756,  99.2329],\n",
              "        [118.7951, 133.1811],\n",
              "        [ 19.8503,  36.7311],\n",
              "        [102.6307, 119.1559]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8JOHN0pKLvp",
        "outputId": "47c71caa-3c9d-4b13-b1aa-bb6fdcfba0f2"
      },
      "source": [
        "targets"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 57.,  69.],\n",
              "        [ 80., 102.],\n",
              "        [118., 132.],\n",
              "        [ 21.,  38.],\n",
              "        [104., 118.],\n",
              "        [ 57.,  69.],\n",
              "        [ 82., 100.],\n",
              "        [118., 134.],\n",
              "        [ 20.,  38.],\n",
              "        [102., 120.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUC8zN7ZMuc4",
        "outputId": "ff524ae5-2511-44f5-bdf6-d4e70460a3c7"
      },
      "source": [
        "model(torch.tensor([[75,63,44.]]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[53.3639, 67.5291]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyGVrkfCMufh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}